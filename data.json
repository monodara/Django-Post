[{"model": "admin.logentry", "pk": 1, "fields": {"action_time": "2025-11-29T08:42:01.187Z", "user": 1, "content_type": 7, "object_id": "1", "object_repr": "RAG - From Basic to Implementation", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 2, "fields": {"action_time": "2026-02-02T07:45:58.966Z", "user": 1, "content_type": 8, "object_id": "1", "object_repr": "AI/ML", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 3, "fields": {"action_time": "2026-02-02T07:46:13.631Z", "user": 1, "content_type": 8, "object_id": "2", "object_repr": "Full-Stack", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 4, "fields": {"action_time": "2026-02-02T07:46:40.185Z", "user": 1, "content_type": 8, "object_id": "3", "object_repr": "Data Analysis & Visualisation", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 5, "fields": {"action_time": "2026-02-02T07:46:44.464Z", "user": 1, "content_type": 8, "object_id": "4", "object_repr": "Game", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 6, "fields": {"action_time": "2026-02-02T07:48:51.657Z", "user": 1, "content_type": 9, "object_id": "1", "object_repr": "React", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 7, "fields": {"action_time": "2026-02-02T07:48:56.736Z", "user": 1, "content_type": 9, "object_id": "2", "object_repr": "Java", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 8, "fields": {"action_time": "2026-02-02T07:49:00.194Z", "user": 1, "content_type": 9, "object_id": "3", "object_repr": "Python", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 9, "fields": {"action_time": "2026-02-02T07:49:04.481Z", "user": 1, "content_type": 9, "object_id": "4", "object_repr": "FastAPI", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 10, "fields": {"action_time": "2026-02-02T07:49:25.211Z", "user": 1, "content_type": 9, "object_id": "5", "object_repr": "TypeScript", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 11, "fields": {"action_time": "2026-02-02T07:49:35.264Z", "user": 1, "content_type": 9, "object_id": "6", "object_repr": "Google Cloud", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 12, "fields": {"action_time": "2026-02-02T07:49:38.485Z", "user": 1, "content_type": 9, "object_id": "7", "object_repr": "Azure", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 13, "fields": {"action_time": "2026-02-02T07:49:53.495Z", "user": 1, "content_type": 9, "object_id": "8", "object_repr": "REST API", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 14, "fields": {"action_time": "2026-02-02T07:50:03.634Z", "user": 1, "content_type": 9, "object_id": "9", "object_repr": "Docker", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 15, "fields": {"action_time": "2026-02-02T07:50:25.190Z", "user": 1, "content_type": 9, "object_id": "10", "object_repr": "CI/CD", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 16, "fields": {"action_time": "2026-02-02T07:50:54.948Z", "user": 1, "content_type": 9, "object_id": "11", "object_repr": "LangChain", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 17, "fields": {"action_time": "2026-02-02T07:51:09.272Z", "user": 1, "content_type": 9, "object_id": "12", "object_repr": "MCP", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 18, "fields": {"action_time": "2026-02-02T07:51:15.949Z", "user": 1, "content_type": 9, "object_id": "13", "object_repr": "RAG", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 19, "fields": {"action_time": "2026-02-02T07:51:40.192Z", "user": 1, "content_type": 9, "object_id": "14", "object_repr": "Ollama", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 20, "fields": {"action_time": "2026-02-02T07:51:55.868Z", "user": 1, "content_type": 9, "object_id": "15", "object_repr": "C++", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 21, "fields": {"action_time": "2026-02-02T07:51:58.931Z", "user": 1, "content_type": 9, "object_id": "16", "object_repr": "C#", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 22, "fields": {"action_time": "2026-02-02T07:52:20.928Z", "user": 1, "content_type": 9, "object_id": "17", "object_repr": "PyTorch", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 23, "fields": {"action_time": "2026-02-02T07:52:25.184Z", "user": 1, "content_type": 9, "object_id": "18", "object_repr": "YOLO", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 24, "fields": {"action_time": "2026-02-02T07:52:37.333Z", "user": 1, "content_type": 9, "object_id": "19", "object_repr": "TensorFlow", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 25, "fields": {"action_time": "2026-02-02T07:53:01.460Z", "user": 1, "content_type": 9, "object_id": "20", "object_repr": "FAISS", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 26, "fields": {"action_time": "2026-02-02T07:53:20.370Z", "user": 1, "content_type": 9, "object_id": "21", "object_repr": "Sqlite", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 27, "fields": {"action_time": "2026-02-02T07:53:25.833Z", "user": 1, "content_type": 9, "object_id": "22", "object_repr": "PostgreSql", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 28, "fields": {"action_time": "2026-02-02T07:53:29.734Z", "user": 1, "content_type": 9, "object_id": "23", "object_repr": "MySql", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 29, "fields": {"action_time": "2026-02-02T07:53:37.269Z", "user": 1, "content_type": 9, "object_id": "24", "object_repr": "MongoDB", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 30, "fields": {"action_time": "2026-02-02T07:54:36.564Z", "user": 1, "content_type": 9, "object_id": "25", "object_repr": "Agents", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 31, "fields": {"action_time": "2026-02-02T07:54:41.320Z", "user": 1, "content_type": 9, "object_id": "26", "object_repr": "LLM", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 32, "fields": {"action_time": "2026-02-02T08:00:45.160Z", "user": 1, "content_type": 10, "object_id": "1", "object_repr": "Multi-Modal AI Assistant for Theme Park Operations", "action_flag": 1, "change_message": "[{\"added\": {}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for Multi-Modal AI Assistant for Theme Park Operations\"}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for Multi-Modal AI Assistant for Theme Park Operations\"}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for Multi-Modal AI Assistant for Theme Park Operations\"}}]"}}, {"model": "admin.logentry", "pk": 33, "fields": {"action_time": "2026-02-02T08:28:42.808Z", "user": 1, "content_type": 10, "object_id": "1", "object_repr": "Multi-Modal AI Assistant for Theme Park Operations", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Github link\"]}}]"}}, {"model": "admin.logentry", "pk": 34, "fields": {"action_time": "2026-02-02T09:35:56.146Z", "user": 1, "content_type": 10, "object_id": "2", "object_repr": "MSignalAI - AI-Powered Stock Market Analysis Platform", "action_flag": 1, "change_message": "[{\"added\": {}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for MSignalAI - AI-Powered Stock Market Analysis Platform\"}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for MSignalAI - AI-Powered Stock Market Analysis Platform\"}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for MSignalAI - AI-Powered Stock Market Analysis Platform\"}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for MSignalAI - AI-Powered Stock Market Analysis Platform\"}}, {\"added\": {\"name\": \"project image\", \"object\": \"Image for MSignalAI - AI-Powered Stock Market Analysis Platform\"}}]"}}, {"model": "admin.logentry", "pk": 35, "fields": {"action_time": "2026-02-02T09:37:57.006Z", "user": 1, "content_type": 10, "object_id": "2", "object_repr": "MSignalAI - AI-Powered Stock Market Analysis Platform", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 36, "fields": {"action_time": "2026-02-02T10:00:18.942Z", "user": 1, "content_type": 10, "object_id": "2", "object_repr": "AI-Powered Stock Market Analysis Platform", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Title\", \"Description\", \"Technologies\"]}}]"}}, {"model": "auth.user", "pk": 1, "fields": {"password": "pbkdf2_sha256$870000$aQHm4zxzFCEGcUUMZ3ndIM$CdehTgf18CAjz1AwBxuJsDTQ4kr3iQjvaJ2Sw0AosRk=", "last_login": "2026-02-02T07:44:42.021Z", "is_superuser": true, "username": "monodara", "first_name": "", "last_name": "", "email": "monodara.lu@gmail.com", "is_staff": true, "is_active": true, "date_joined": "2025-11-29T08:38:59.589Z", "groups": [], "user_permissions": []}}, {"model": "sessions.session", "pk": "1ufefx9pruaux3m7172kortnqhkzxdmf", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpOYO19q5xADlSnFSIu0OkFNC-mXkvlmBbW9oGLWlCdmaSnX63DOVBfQd4h36beZn7ukyZ7wo_6ODXGel5Ody_gwajfWvnSxQmZyFCVNppK1HZ6qzXvhoIOlepyUCMWZiKYKUoKANRAFCWqLD3B7-_N80:1vmoby:zt0-jKJ9kCcwg8dDjL85dmJdoScyM3Kwacr1aAhGr7I", "expire_date": "2026-02-16T07:44:42.022Z"}}, {"model": "sessions.session", "pk": "5fhyppdfajkmp1rdenrxmdk39hkei3qq", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpOYO19q5xADlSnFSIu0OkFNC-mXkvlmBbW9oGLWlCdmaSnX63DOVBfQd4h36beZn7ukyZ7wo_6ODXGel5Ody_gwajfWvnSxQmZyFCVNppK1HZ6qzXvhoIOlepyUCMWZiKYKUoKANRAFCWqLD3B7-_N80:1vPGUC:iyzqasH0gfDvnzAIp11ElWjijADKl2Q47Gm_X-3x_Zk", "expire_date": "2025-12-13T08:39:20.127Z"}}, {"model": "blog.post", "pk": 1, "fields": {"author": 1, "title": "Retrieval-Augmented Generation (RAG): From the Basics to Implementation", "subtitle": "Understand and implement an RAG system from scratch", "text": "<p>A RAG-based QA assistant can serve a wide range of domains &mdash; from e-commerce customer support and public service chatbots to research assistants, healthcare information systems, and legal precedents analysis.</p>\r\n\r\n<h5><big>Why RAG?</big></h5>\r\n\r\n<p>While LLMs are becoming more powerful every day, they still have key limitations: they are trained on enormous datasets that are nonetheless only a partial and outdated snapshot of available knowledge. &ldquo;Partial&rdquo; means that the model&rsquo;s training corpus includes public websites, books, and codebases, but never internal documents such as corporate manuals, proprietary research data, or user-specific data. &ldquo;Outdated&rdquo; means that once a model is released, it has no awareness of new events or evolving facts.</p>\r\n\r\n<p>When faced with a question beyond its training data, the model is prone to a typical problem &mdash; hallucination, that is, the LLM may guess and fabricate an answer that appears plausible but is actually false. One of the technologies that can help address this problem is RAG, which tells LLM to generate a rational response based on some truth.</p>\r\n\r\n<p>In a nutshell, an LLM is a &lsquo;brain with memory of what happened outside but no updates&rsquo;, while RAG empowers it to expand its vision.</p>\r\n\r\n<h5><big>What is RAG?</big></h5>\r\n\r\n<p>Retrieval-Augmented Generation is still a form of generation, which is performed by LLMs. When you chat with an intelligent QA assistant, the user experience is not much different from what you have had with OpenAI ChatGPT. What is seen on stage in both scenarios is that you ask a question and get a response from the chatbot.</p>\r\n\r\n<p>Behind the scenes, however, there is something more that has happened &mdash; the retrieval of relevant information to augment the LLM&rsquo;s context. For example, when answering real-time questions such as current weather, stock prices, or exchange rates, the RAG system retrieves information from live sources before generating a response. And to supplement the model with the understanding of internal or private materials, retrieve from the database where the knowledge base is stored, which is illustrated as follows.</p>\r\n\r\n<p><img alt=\"\" src=\"/media/uploads/2025/11/29/rag-architecture.png\" style=\"height:496px; width:760px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>Similar to how we store and retrieve data using SQL (like PostgreSQL) and NoSQL (like MongoDB), this time we still store our data in a pool, except the fact that the data is highly unstructured and is massive and cannot be searched by keywords. Here comes the concept of vector and embedding.</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h3><big><strong>Everything Can Be Embedded.</strong></big></h3>\r\n\r\n<p>As we say about OOP, &ldquo;Everything can be an object&rdquo;, now we say, &ldquo;Everything can be embedded.&rdquo; That is, everything can be represented as a vector.</p>\r\n\r\n<p>In this context,&nbsp;<strong>embeddings are vectors</strong>. They are&nbsp;<strong>vectors with meanings</strong>. As neural networks operate purely on numbers &mdash; performing operations such as multiplication and addition, we have to transform texts, images, and so on, which we human beings can comprehend, into a numeric form by which neural networks can comprehend our communication material. This form is called embedding, a vector representing the meaning of a piece of natural language. And the pool storing embeddings is called a&nbsp;<strong>vector database</strong>.</p>\r\n\r\n<h3>Representing Meaning in Multiple Dimensions</h3>\r\n\r\n<p>These vectors are high-dimensional, normally hundreds of dimensions, 512d, 1024d, something like that. While we can visualize a 2D vector in a plane coordinate system as (x, y) and then add the third axis to represent a 3D vector as (x, y, z), it is difficult to visualize a vector with more than 3 dimensions. But maybe we can think in this way. One dimension represents one trait of a piece of text. Take the following as an example.</p>\r\n\r\n<p>All of &ldquo;cat&rdquo;, &ldquo;pine&rdquo;, &ldquo;table&rdquo;, &ldquo;bee&rdquo;, &ldquo;bat&rdquo;, &ldquo;whale&rdquo; represent a tangible entity..</p>\r\n\r\n<p>Are they creatures?&nbsp;<strong><em>cat, pine, bee, bat, whale=[1,1], table=[1,0]</em></strong></p>\r\n\r\n<p>Are they animals?&nbsp;<strong><em>cat, bee, bat, whale=[1,1,1], pine=[1,1,0], table=[1,0,0]</em></strong></p>\r\n\r\n<p>Are they mammals?&nbsp;<strong><em>cat, bat, whale=[1,1,1,1], bee=[1,1,1,0], pine=[1,1,0,0], table=[1,0,0,0]</em></strong></p>\r\n\r\n<p>Do they have wings?&nbsp;<strong><em>cat, whale=[1,1,1,1,0], bat=[1,1,1,1,1], bee=[1,1,1,0,1], pine=[1,1,0,0,0], table=[1,0,0,0,0]</em></strong></p>\r\n\r\n<p>Do they live in water?&nbsp;<strong><em>whale=[1,1,1,1,0,1], cat=[1,1,1,1,0,0], bat=[1,1,1,1,1,0], bee=[1,1,1,0,1,0], pine=[1,1,0,0,0,0], table=[1,0,0,0,0,0]</em></strong></p>\r\n\r\n<p>&hellip;&hellip;</p>\r\n\r\n<p>When searching for similarity with &ldquo;tiger&rdquo; in the above-mentioned words, &ldquo;cat&rdquo; will win.</p>\r\n\r\n<p>With the same logic, a high-dimensional vector represents hundreds of traits of a piece of text (what we call a &ldquo;chunk&rdquo;), an image, or anything. Values in the array are continuous rather than discrete (0s and 1s).</p>\r\n\r\n<h3><strong><big>How to Embed Documents</big></strong></h3>\r\n\r\n<p>How to embed them, i.e., to transform documents into vectors? Fortunately, a wide collection of&nbsp;<a href=\"https://huggingface.co/models?search=embedding\" rel=\"noopener ugc nofollow\" target=\"_blank\">trained models</a>&nbsp;(click and find available resources) is ready for use. We&rsquo;ll explore the internal mechanisms later &mdash; for now, let&rsquo;s focus on the workflow.</p>\r\n\r\n<p>The following code is an example of how to use CLIP-vit-base-patch32 to embed an image.</p>\r\n\r\n<pre>\r\n<code>from transformers import CLIPProcessor, CLIPModel # transformers is a framework for model usage, developed by Hugging Face. Install it using &quot;pip install transformers&quot;\r\n# Load CLIP model and processor\r\nclip_model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)\r\nclip_processor = CLIPProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)\r\n\r\nfrom PIL import Image # Before it, run &quot;pip install Pillow&quot;\r\ndef get_image_embedding(image_path):\r\nimage = Image.open(image_path)\r\ninputs = clip_processor(images=image, return_tensors=&quot;pt&quot;)\r\nwith torch.no_grad():\r\nimage_features = clip_model.get_image_features(**inputs)\r\nreturn image_features[0].numpy()\r\n\r\n&#39;&#39;&#39;\r\nCall the function with an image and print the returned result,\r\nyou will get an array similar to\r\n[-0.0132809 0.04572856 0.08792043 -0.03914355 -0.02482264\r\n0.05938271 0.0719912 -0.00396497 0.02297862 -0.0803934\r\n0.01876233 0.05230444 -0.03180214 0.0940239 -0.06793992\r\n...\r\n0.01547239 -0.01027456 0.04728566]\r\nIt contains 512 values because openai/clip-vit-base-patch32 transform an image into a 512d vector.\r\n&#39;&#39;&#39;</code>\r\n</pre>\r\n\r\n<p>&nbsp;</p>", "created_date": "2025-11-29T08:40:32Z", "published_date": "2025-11-29T13:55:57.376Z"}}, {"model": "blog.post", "pk": 2, "fields": {"author": 1, "title": "Sample title", "subtitle": null, "text": "Test", "created_date": "2025-11-29T10:36:42.790Z", "published_date": null}}, {"model": "blog.post", "pk": 3, "fields": {"author": 1, "title": "Function Calling + ReAct— From Generation to Agent", "subtitle": null, "text": "In the previous article, I introduced how to build an intelligent Q&A assistant based on the RAG (Retrieval-Augmented Generation) architecture. While this approach helps reduce hallucinations and grounds responses in domain-specific knowledge, it has limitations. For instance, consider questions like:\r\n\r\n“When should I visit the theme park to avoid peak seasons?” “I plan to visit the park next Sunday. What will the weather be like?”\r\n\r\nIn such cases, the assistant may query the vector database but still respond: “I’m happy to help, but I don’t have information on the visit flow or weather forecast.”\r\n\r\nClearly, more capabilities are needed.\r\n\r\nThis article will introduce function calling and the ReAct pattern, demonstrating how to empower the assistant to reason, act, and utilize external tools effectively. We will explore technologies like OpenAI, LangChain, Text-to-SQL, and Qwen-Agent.", "created_date": "2025-11-29T12:19:58.121Z", "published_date": "2025-11-29T12:19:58.127Z"}}, {"model": "portfolio.projectgroup", "pk": 1, "fields": {"name": "AI/ML"}}, {"model": "portfolio.projectgroup", "pk": 2, "fields": {"name": "Full-Stack"}}, {"model": "portfolio.projectgroup", "pk": 3, "fields": {"name": "Data Analysis & Visualisation"}}, {"model": "portfolio.projectgroup", "pk": 4, "fields": {"name": "Game"}}, {"model": "portfolio.technology", "pk": 1, "fields": {"name": "React"}}, {"model": "portfolio.technology", "pk": 2, "fields": {"name": "Java"}}, {"model": "portfolio.technology", "pk": 3, "fields": {"name": "Python"}}, {"model": "portfolio.technology", "pk": 4, "fields": {"name": "FastAPI"}}, {"model": "portfolio.technology", "pk": 5, "fields": {"name": "TypeScript"}}, {"model": "portfolio.technology", "pk": 6, "fields": {"name": "Google Cloud"}}, {"model": "portfolio.technology", "pk": 7, "fields": {"name": "Azure"}}, {"model": "portfolio.technology", "pk": 8, "fields": {"name": "REST API"}}, {"model": "portfolio.technology", "pk": 9, "fields": {"name": "Docker"}}, {"model": "portfolio.technology", "pk": 10, "fields": {"name": "CI/CD"}}, {"model": "portfolio.technology", "pk": 11, "fields": {"name": "LangChain"}}, {"model": "portfolio.technology", "pk": 12, "fields": {"name": "MCP"}}, {"model": "portfolio.technology", "pk": 13, "fields": {"name": "RAG"}}, {"model": "portfolio.technology", "pk": 14, "fields": {"name": "Ollama"}}, {"model": "portfolio.technology", "pk": 15, "fields": {"name": "C++"}}, {"model": "portfolio.technology", "pk": 16, "fields": {"name": "C#"}}, {"model": "portfolio.technology", "pk": 17, "fields": {"name": "PyTorch"}}, {"model": "portfolio.technology", "pk": 18, "fields": {"name": "YOLO"}}, {"model": "portfolio.technology", "pk": 19, "fields": {"name": "TensorFlow"}}, {"model": "portfolio.technology", "pk": 20, "fields": {"name": "FAISS"}}, {"model": "portfolio.technology", "pk": 21, "fields": {"name": "Sqlite"}}, {"model": "portfolio.technology", "pk": 22, "fields": {"name": "PostgreSql"}}, {"model": "portfolio.technology", "pk": 23, "fields": {"name": "MySql"}}, {"model": "portfolio.technology", "pk": 24, "fields": {"name": "MongoDB"}}, {"model": "portfolio.technology", "pk": 25, "fields": {"name": "Agents"}}, {"model": "portfolio.technology", "pk": 26, "fields": {"name": "LLM"}}, {"model": "portfolio.project", "pk": 1, "fields": {"group": 1, "title": "Multi-Modal AI Assistant for Theme Park Operations", "description": "<p><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\">An advanced, multi-modal AI assistant system for a theme park, integrating </span><code>RAG</code><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\">, </span><code>Text2SQL</code><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\">, </span><code>Function Calling</code><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\">, and </span><code>MCP (Model Context Protocol)</code><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\"> that can answer questions related to visiting tips, previous flows, transportation routes, weather information, etc.</span></p>", "github_link": "https://github.com/monodara/Intelligent_QA_Assistant", "technologies": [3, 4, 11, 13, 14, 20, 25, 26]}}, {"model": "portfolio.project", "pk": 2, "fields": {"group": 1, "title": "AI-Powered Stock Market Analysis Platform", "description": "<p><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\">A web application designed to provide comprehensive stock market analysis, leveraging AI to interpret market data, technical indicators, fundamental metrics, and news. The frontend is deployed on </span><code>GitHub Pages</code><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\">, while the backend runs as a serverless FastAPI service on </span><code>Google Cloud Run</code><span style=\"background-color:rgb(255,255,255);color:rgb(31,35,40);\">.</span></p>", "github_link": "https://github.com/monodara/AI-Powered-Stock-Analysis", "technologies": [1, 3, 4, 6, 9, 11, 21, 25]}}, {"model": "portfolio.projectimage", "pk": 1, "fields": {"project": 1, "image": "projects/Multi-Modal AI Assistant for Theme Park Operations/user_quick_question.png"}}, {"model": "portfolio.projectimage", "pk": 2, "fields": {"project": 1, "image": "projects/Multi-Modal AI Assistant for Theme Park Operations/user_chat.png"}}, {"model": "portfolio.projectimage", "pk": 3, "fields": {"project": 1, "image": "projects/Multi-Modal AI Assistant for Theme Park Operations/admin_dashboard.png"}}, {"model": "portfolio.projectimage", "pk": 4, "fields": {"project": 2, "image": "projects/MSignalAI - AI-Powered Stock Market Analysis Platform/ai_chat.png"}}, {"model": "portfolio.projectimage", "pk": 5, "fields": {"project": 2, "image": "projects/MSignalAI - AI-Powered Stock Market Analysis Platform/news.png"}}, {"model": "portfolio.projectimage", "pk": 6, "fields": {"project": 2, "image": "projects/MSignalAI - AI-Powered Stock Market Analysis Platform/charts.png"}}, {"model": "portfolio.projectimage", "pk": 7, "fields": {"project": 2, "image": "projects/MSignalAI - AI-Powered Stock Market Analysis Platform/ai_analysis.png"}}, {"model": "portfolio.projectimage", "pk": 8, "fields": {"project": 2, "image": "projects/MSignalAI - AI-Powered Stock Market Analysis Platform/fundamentals.png"}}]